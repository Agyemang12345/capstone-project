{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3b6d92",
   "metadata": {},
   "source": [
    "# üåø Plant Disease Detection System - Training Notebook\n",
    "\n",
    "This comprehensive Jupyter notebook covers the entire workflow for building a plant disease detection system using deep learning:\n",
    "\n",
    "1. **Dataset Preparation**: Loading and preprocessing leaf images\n",
    "2. **Model Training**: Training multiple CNN architectures (MobileNetV2, ResNet50, EfficientNetB0)\n",
    "3. **Evaluation**: Analyzing model performance with metrics and visualizations\n",
    "4. **Deployment**: Creating a Streamlit web application\n",
    "5. **Integration**: Instructions for custom dataset integration and deployment\n",
    "\n",
    "**Author**: AI Development Team  \n",
    "**Date**: 2024  \n",
    "**Framework**: TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98917d4f",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configure for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Check TensorFlow version and GPU availability\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.test.is_built_with_cuda()}\")\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(f\"GPUs detected: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "    for gpu in tf.config.list_physical_devices('GPU'):\n",
    "        print(f\"  - {gpu}\")\n",
    "else:\n",
    "    print(\"No GPU detected. Using CPU.\")\n",
    "\n",
    "# Set up matplotlib style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd283c3",
   "metadata": {},
   "source": [
    "## Section 2: Dataset Preparation and Preprocessing\n",
    "\n",
    "Dataset Structure Expected:\n",
    "```\n",
    "dataset/\n",
    "‚îú‚îÄ‚îÄ Healthy/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img2.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ Powdery_Mildew/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img2.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ Leaf_Spot/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ img2.jpg\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbd878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "IMG_SIZE = 224\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Set your data directory here\n",
    "DATA_DIR = \"../data/raw_data\"  # Change this to your dataset path\n",
    "\n",
    "# Check if data directory exists\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"‚ö†Ô∏è Data directory not found at {DATA_DIR}\")\n",
    "    print(\"Please ensure your dataset is organized as shown above.\")\n",
    "else:\n",
    "    print(f\"‚úì Data directory found at {DATA_DIR}\")\n",
    "\n",
    "# Function to load dataset from folder structure\n",
    "def load_dataset_from_folder(data_dir, img_size=224):\n",
    "    \"\"\"\n",
    "    Load all images from nested folder structure (class folders)\n",
    "    Returns: images array, labels array, class names list\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = []\n",
    "    \n",
    "    # Get all disease class directories\n",
    "    disease_dirs = sorted([d for d in os.listdir(data_dir) \n",
    "                          if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    \n",
    "    class_names = disease_dirs\n",
    "    print(f\"Found {len(class_names)} disease classes: {class_names}\\n\")\n",
    "    \n",
    "    # Load images from each disease folder\n",
    "    for class_idx, disease_name in enumerate(disease_dirs):\n",
    "        disease_path = os.path.join(data_dir, disease_name)\n",
    "        image_files = [f for f in os.listdir(disease_path) \n",
    "                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n",
    "        \n",
    "        print(f\"Loading {len(image_files)} images from {disease_name}...\")\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            try:\n",
    "                img_path = os.path.join(disease_path, img_file)\n",
    "                # Read image\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    # Convert BGR to RGB\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    # Resize\n",
    "                    img = cv2.resize(img, (img_size, img_size))\n",
    "                    # Normalize to [0, 1]\n",
    "                    img = img.astype(np.float32) / 255.0\n",
    "                    \n",
    "                    images.append(img)\n",
    "                    labels.append(class_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_file}: {e}\")\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    print(f\"\\n‚úì Loaded {len(images)} images total\")\n",
    "    print(f\"Image shape: {images.shape}\")\n",
    "    print(f\"Label distribution:\\n{pd.Series(labels).value_counts().sort_index()}\\n\")\n",
    "    \n",
    "    return images, labels, class_names\n",
    "\n",
    "# Load dataset (uncomment after providing data)\n",
    "# images, labels, class_names = load_dataset_from_folder(DATA_DIR)\n",
    "print(\"Ready to load dataset. Update DATA_DIR path and uncomment the load_dataset_from_folder() call.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da663b2",
   "metadata": {},
   "source": [
    "## Section 3: Data Augmentation and Train/Validation/Test Split"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
